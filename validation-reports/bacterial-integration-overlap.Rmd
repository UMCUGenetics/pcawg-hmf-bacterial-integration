---
title: "Bacterial and viral integration"
author: "Roel Janssen"
date: "10/27/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

## Overlap the PCAWG findings with our KRAKEN2 findings

To execute the query, we need to load `RCurl`, and to parse the results, we need `jsonlite`.

```{r echo=T, eval=FALSE, results='hide'}
library(RCurl, quietly=TRUE)
library(jsonlite, quietly=TRUE)
```

Furthermore, we need to obtain a `token` and the `projectId` from the SPARQLing-genomics endpoint:

```{r,echo=T,eval=FALSE,results='hide'}
token     <- Sys.getenv("SG_TOKEN")
projectId <- "665d953ae62d3323385cb79f652949b1b09f6227ce74c87d2e63c2b6ee4b12a0"
query     <- "PREFIX col: <sg://0.99.11/table2rdf/Column/>
PREFIX sg:  <https://sparqling-genomics.org/0.99.11/>

SELECT DISTINCT STR(?donor_id) AS ?donor ?taxonid ?reads ?fragments
WHERE {
  GRAPH <temp://pcawg-consensus-tumor-bacterial-integration> {
    ?r1 col:icgc_donor_id              ?donor_id ;
        col:ncbi_taxonid_genus         ?taxonid ;
        col:number_of_supporting_reads ?reads .
  }

  GRAPH <temp://pipeline5-kraken-tumor-bacterial-integration> {
    ?r2 col:icgc_donor_id              ?donor_id2 ;
        col:ncbi_taxon_id              ?taxonid ;
        col:fragments_covered          ?fragments .
  }

  FILTER (STR(?donor_id) = ?donor_id2)
  FILTER (?fragments > 0)
}
ORDER BY DESC(?donor_id)"
```

Use RCurl to perform the query:

```{r,echo=T,eval=FALSE,results='hide'}
accumulator <- basicTextGatherer()
endpoint    <- "https://node2.sparqling-genomics.org/sparql"
cookie      <- paste0("SGSession=", token, sep="")

accumulator$reset()
curlPerform(url           = paste0(endpoint, "?project-id=", projectId),
            httpheader    = c("Accept"       = "application/json",
                              "Cookie"       = cookie,
                              "Content-Type" = "application/sparql-update"),
            customrequest = "POST",
            postfields    = query,
            writefunction = accumulator$update)

jsonData    <- accumulator$value()
```

Parse the data with `jsonlite`:

```{r, echo=TRUE, eval=FALSE, results='hide'}
results <- fromJSON(jsonData)
```

## Comparing reported supporting reads from PCAWG with supporting reads found by pipeline5 KRAKEN2

```{r echo=T, results='hide'}
library(ggplot2, quietly=TRUE)
library(reshape2, quietly=TRUE)
data <- melt(results[,c("donor", "fragments", "reads")])
plot <- ggplot(data = data, aes(fill=variable, y=value, x=donor))  +
          geom_bar(stat="identity", position = "dodge")            +
          theme(axis.text.x=element_text(angle = 90, vjust = 0.5)) +
          labs (title = "No. fragments vs no. reads.")             +
          ylab("Number of fragments/reads")                        +
          xlab("Donor")
```

```{r echo=F, results='show'}
plot
```


## Linear regression

```{r echo=TRUE, results='hide'}
data         <- results[,c("taxon_name", "fragments", "reads")]

data$fragments_log10 <- log(data$fragments, base=10)
data$reads_log10 <- log(data$reads, base=10)
data$taxonid <- as.factor(data$taxon_name)
fit          <- lm(fragments_log10 ~ reads_log10, data = data)

r_squared    <- summary(fit)$adj.r.squared
intercept    <- fit$coef[[1]]
slope        <- fit$coef[[2]]
p_value      <- summary(fit)$coef[2,4]

title        <- sprintf("Adj. R2 = %.5f, Int. = %.5f, Slope = %.5f, P = %.5f",
                     r_squared, intercept, slope, p_value)

plot         <- ggplot(data, aes(x = fragments_log10, y = reads_log10))      +
                    geom_point(aes(colour=taxon_name),size=2)                +
                    stat_smooth(method = "lm", col = "#ca0020")              +
                    labs(title = title)                                      +
                    xlab(c("pipeline 5 fragment support"))                   +
                    ylab(c("PCAWG read support"))
```

```{r echo=FALSE, results='show'}
plot
```

```{r, results='hide', echo=FALSE}
# This cleans up the environment and enforces a round of garbage collection.
remove (list = ls())
gc(verbose = FALSE, reset = TRUE, full = TRUE)
```

## Overlap pipeline5/KRAKEN2 output with PCAWG findings

```{r, eval=TRUE, echo=FALSE, results='hide'}
# Well, we just cleaned up, but we need the following:
library(RCurl, quietly=TRUE)
library(jsonlite, quietly=TRUE)
token     <- Sys.getenv("SG_TOKEN")
projectId <- "665d953ae62d3323385cb79f652949b1b09f6227ce74c87d2e63c2b6ee4b12a0"
```

```{r}
query <- "PREFIX col:         <sg://0.99.11/table2rdf/Column/>

SELECT DISTINCT ?donor_id ?taxon_id ?taxon_name 
                ?kraken_covered ?pcawg_supporting_reads
WHERE {
  GRAPH <temp://pcawg-kraken-merged> {
    ?r col:donor_id                ?donor_id .
    ?r col:icgc_taxon_id           ?taxon_id .
    ?r col:taxon_name              ?taxon_name .
    ?r col:kraken_covered          ?kraken_covered .
    ?r col:pcawg_supporting_reads  ?pcawg_supporting_reads .
  }

  # Do not include human reads.
  FILTER (?taxon_id != 9605)
}"

accumulator <- basicTextGatherer()
endpoint    <- "https://node1.sparqling-genomics.org/sparql"
cookie      <- paste0("SGSession=", token, sep="")

accumulator$reset()
curlPerform(url           = paste0(endpoint, "?project-id=", projectId),
            httpheader    = c("Accept"       = "application/json",
                              "Cookie"       = cookie,
                              "Content-Type" = "application/sparql-update"),
            customrequest = "POST",
            postfields    = query,
            writefunction = accumulator$update)

jsonData    <- accumulator$value()
results     <- fromJSON(jsonData)
```

```{r echo=TRUE, results='hide'}
data                 <- results[,c("taxon_name", "kraken_covered", 
                                   "pcawg_supporting_reads")]
data$fragments_log10 <- log(data$kraken_covered, base=10)
data$reads_log10     <- log(data$pcawg_supporting_reads, base=10)

# The log10 transformation leads to infinite values for 0, 
# so we reset those to 0.
data$fragments_log10[is.infinite(data$fragments_log10)] <- 0
data$reads_log10[is.infinite(data$reads_log10)]         <- 0

data$taxonname <- as.factor(data$taxon_name)
fit            <- lm(fragments_log10 ~ reads_log10, data = data)

r_squared    <- summary(fit)$adj.r.squared
intercept    <- fit$coef[[1]]
slope        <- fit$coef[[2]]
p_value      <- summary(fit)$coef[2,4]

title        <- sprintf("Adj. R2 = %.5f, Int. = %.5f, Slope = %.5f, P = %.5f",
                     r_squared, intercept, slope, p_value)
```

```{r, echo=TRUE, results='hide', fig.width=30, fig.height=15}
plot         <- ggplot(data, aes(x = fragments_log10, y = reads_log10))      +
                    geom_point(aes(colour=taxon_name),size=2)                +
                    stat_smooth(method = "lm", col = "#ca0020")              +
                    labs(title = title)                                      +
                    xlab(c("pipeline 5 fragment support"))                   +
                    ylab(c("PCAWG read support"))

plot
```

```{r, echo=FALSE, results='hide'}
# Clean up the environment again.
remove (list = ls())
gc (verbose = FALSE, reset = TRUE, full = TRUE)
```
